www.nature.com/scientificreports/![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.001.png)

www.nature.com/scientificreports![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.002.png)

` `![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.003.png)![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.004.png)

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.005.png)

**OPEN Screening COVID‑19 by Swaasa ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.006.png)**

**AI platform using cough sounds: a cross‑sectional study**

**Padmalatha Pentakota 1, Gowrisree Rudraraju 2*****, Narayana Rao Sripada 2,** 

**Baswaraj Mamidgi 2, Charishma Gottipulla 2, Charan Jalukuru 2, Shubha Deepti Palreddy 2, Nikhil Kumar Reddy Bhoge 2, Priyanka Firmal 2, Venkat Yechuri 2, Manmohan Jain 2, Venkata Sudhakar Peddireddi 1, Devi Madhavi Bhimarasetty 1, S. Sreenivas 1,** 

**Kesava Lakshmi Prasad K 1, Niranjan Joshi 3, Shibu Vijayan 4, Sanchit Turaga 5 &** 

**Vardhan Avasarala 6**

**The Advent of Artificial Intelligence (AI) has led to the use of auditory data for detecting various diseases, including COVID19. SARSCoV 2 infection has claimed more than six million lives to date and therefore, needs a robust screening technique to control the disease spread. In the present study we created and validated the Swaasa AI platform, which uses the signature cough sound and symptoms presented by patients to screen and prioritize COVID19 patients. We collected cough data from 234 COVID19 suspects to validate our Convolutional Neural Network (CNN) architecture and Feedforward Artificial Neural Network (FFANN) (tabular features) based algorithm. The final output from both models was combined to predict the likelihood of having the disease. During the clinical validation phase, our model showed a 75.54% accuracy rate in detecting the likely presence of COVID 19, with 95.45% sensitivity and 73.46% specificity. We conducted pilot testing on 183 presumptive COVID subjects, of which 58 were truly COVID19 positive, resulting in a Positive Predictive Value** 

**of 70.73%. Due to the high cost and technical expertise required for currently available rapid screening methods, there is a need for a costeffective and remote monitoring tool that can serve as a preliminary screening method for potential COVID19 subjects. Therefore, Swaasa would be highly beneficial in detecting the disease and could have a significant impact in reducing its spread.**

` `e SARS-CoV-2 infection first surfaced at the end of December 2019, affecting nearly 769 million people across the globe[1](#_page8_x155.00_y270.36).  e virus transmission begins once a healthy individual is exposed to the respiratory droplets originating from an infected person.  e average incubation period for the disease symptoms to manifest var - ies from 2 14 days[2](#_page8_x155.00_y278.36).  e early symptoms comprise dry cough, fever, fatigue, and loss of smell and taste. Some patients may experience shortness of breath, cardiac issues, and pneumonia-like symptoms, which can ultimately result in death. Many people are also experiencing post-covid acute symptoms which affect their overall health status[3](#_page8_x155.00_y304.36),[4](#_page8_x155.00_y321.36).  e containment of COVID-19 outbreaks became very difficult because of the unavailability of quick and effective pre-screening techniques. Most of the viral and serological testing methods available are very expensive, time-consuming, require technical expertise and are not always reliable, especially in detecting the new SARC-CoV-2 variants[5](#_page8_x155.00_y329.36),[6](#_page8_x155.00_y346.36).

Cough is a common symptom of COVID-19[7](#_page8_x155.00_y363.36). Physiologically, coughing is responsible for removing any obstruction in the airways via explosive expulsion of the air[8](#_page8_x155.00_y389.36). While this serves some benefit to the patient, it o en results in the dissemination of airborne infectious aerosols9[,1](#_page8_x155.00_y406.36)[0. ](#_page8_x155.00_y423.36) at being said, cough is very useful in diagnosing and detecting various disease processes. Literature suggests that glottis movement during a cough can be used to differentiate between various respiratory conditions including pertussis, bronchitis and  asthma[11](#_page8_x155.00_y440.36)[,12](#_page8_x155.00_y457.36). With cough being such a prominent and unique aspect of multiple disease processes, more reports suggest its possible use in detecting Covid-1[913](#_page8_x155.00_y474.36)[,14](#_page8_x155.00_y491.36). Cough sound analysis has proven effective for diagnosing diseases like tuberculosis (TB). However, the application of AI cough analysis for COVID-19 detection has not been fully 

1Andhra  Medical  College,  Visakhapatnam,  India.  2Salcit  Technologies,  Jayabheri  Silicon  Towers,  Hyderabad, India.  3C-CAMP,  Bangalore,  India.  4Qure.Ai  Technologies,  Oberoi  Commerz  II,  Mumbai,  India.  5NDORMS, University of Oxford, Oxford, UK. 6Otolaryngology - Head and Neck Surgery, Northeast Ohio Medical University, Rootstown, USA. *email: gowri@salcit.in

explored. Further research and validation are necessary to ascertain its accuracy and potential usefulness in the screening of COVID-19.

In the past few years, substantial strides have been made exploring the utility of AI in medicine particularly in using machine learning techniques to analyse cough sounds for multiple respiratory  pathologies[15](#_page8_x155.00_y516.36)[,16](#_page8_x155.00_y533.36). In fact, various groups have highlighted the benefits of these machine-learning techniques in detecting COVID-19 over pre-screening methods such as, RT-PCR[17](#_page8_x155.00_y550.36)  [21](#_page8_x155.00_y618.36). While there is significant interest and investigation in developing an AI-based model for Covid-19 detection, no current tools are available in the market to our knowledge.  is 

is largely due to the difficulty in the acquisition of cough sound data from crowdsource open access datasets and lack of proper technical/clinical validations to scale up these tools for mass screening of COVID  subjects[22](#_page8_x155.00_y644.36)[,23](#_page8_x155.00_y661.36).

Our research provides a comprehensive methodology for developing, validating, and testing the  Swaasa AI platform  as a rapid Point of Care tool to screen and prioritize potential COVID-19 cases.  is So ware as 

a Medical Device (SaMD) evaluates SARS-CoV-2 infection through analysis of a 10-s cough sound recording. Our study is distinct in that it includes cough recordings from COVID-19 positive patients, healthy subjects, and patients with various respiratory conditions. We conducted a feature analysis of known COVID-19 and non- COVID-19 coughs and discovered a distinct signature in COVID-19 coughs that a machine learning model can identify. Unlike prior research that relied on crowdsource cough databases for data collection, this study uses data acquired in a clinical setting from a diverse and comprehensive background bolstering its utility as a robust model. We trained two parallel models, a CNN model along with a FFANN model and merged their final layers to increase accuracy. Our model achieved 96% accuracy on the test dataset during derivation and 76% during validation phase, with a positive prediction value of 70.73% in real-time scenarios.  is cost-effective, non- invasive screening tool is valuable for detecting COVID-19 cases. However, further validation studies involving larger and more diverse populations are necessary to improve accuracy and applicability globally.

**Materials and methods**

**Sample size estimation**

To determine the sample size for our study, we employed a formula that incorporates various assumptions about key variables.  e formula, n  = Z2\*P(1 − P)/d2, involved selecting values for Z (level of confidence), P (anticipated prevalence), and d (precision corresponding to the effect size)[24](#_page8_x155.00_y678.36). According to the sample size calculation, a total of 1152 subjects was appropriate for validating if the device could detect COVID-19 with a 90% sensitivity on considering a 2.5% error for a 95% confidence interval (CI) and a prevalence of 0.75%. Considering all the conditions, we pooled the data collected from two individual clinical trial studies for developing and evaluat- ing our model. We considered a total of 1052 participants in the present study, out of which 62% were controls. Control subjects comprise healthy individuals as well as subjects who were displaying various respiratory disease symptoms but were negative for COVID-19 via RT-PCR. To prevent any potential bias in the model, we ensured that an equal number of COVID-19 and non-COVID-19 subjects were used during the training process.

**Data collection**

` `e cough data was collected at Andhra Medical College, Visakhapatnam, India as a part of four individual studies entitled  Development, Validation, Pilot Deployment of an ultra-scalable technology Swaasa AI, as an auxiliary to COVID-19 Rapid test  and  COVID-19 Cough Sound Analysis Using Swaasa Artificial Intel- ligence Platform .  e studies were registered under Clinical Trials Registry- India CTRI/2021/09/036,489, CTRI/2021/07/035,096, and were begun a er getting the approval from the Andhra Medical College Institu- tional Ethics Committee (IEC).  e methodologies performed throughout the study were in accordance with the set guidelines. A duly signed written informed consent was also collected from all the enrolled subjects before starting the trial, which was followed by collection of the demographic details and the vital signs. Patients were then interviewed for the Part I of the St. George s Respiratory Questionnaire (SGRQ) and COVID-19 symptoms in order to gather their  symptoms[25](#_page8_x155.00_y695.36). Next, the cough sound was collected by a trained health care personnel using a smartphone (Android or iPhone).  e participants were instructed to take a deep breath and cough 2 3 times until the recording stopped i.e., 10 s. We also provided specific instructions to each participant, including sitting comfortably in a quiet place, holding the recording device 4 8 inches away from their mouth at 90-degree angle with their face. We also applied a noise reduction algorithm to filter out background noise in the audio record- ings. Valid coughs were detected using a cough/non-cough classifier, which screened the dataset for coughs with high background noise. We also implemented several safety measures to prevent the transmission of disease, including requiring participants to wear a surgical mask during the audio recording process and cleaning the phone used for recording a er each recording.

Following the cough sample collection, the patients were subjected to a reference standard test (RT-PCR).  e inclusion criteria for the enrolment are that the Patients must be (a) male and female patients age ≥ 18 years, who were (b) recently diagnosed with COVID-19 (for validation phase only) and were (c) able to read, understand and sign the informed consent form. Whereas male and female patients age < 18 years, who were (b) on ventilators support, (c) asymptomatic patients attending isolation ward for COVID-19 testing and (d) Pregnant females were completely excluded from the current study. COVID-19 precautionary and infection control measures were followed strictly.

**Model development and training**

In the derivation phase of the study, a machine learning-based model was developed and trained for the detection of COVID-19 using cough sounds. A total of 803 cough events were extracted from cough data collected form 252 subjects which were tested positive for COVID-19 by RT-PCR. Event extraction was carried out using the moving window signal standard deviation technique, and a cough/non-cough classifier was used to segregate the events into actual coughs and non-coughs. A total of 1946 cough events were extracted from both COVID-19 likely-Yes and No subjects.  e features were extracted from both the time and frequency domain of each cough event, resulting in 209 features that includes information about age, gender, and various audio features such as Mel Frequency Cepstral Coefficients (MFCC), spectral features (spectral centroid, spectral roll-off, etc.), chroma features, contrast features, tonnentz features, zero-crossing rate (ZCR), energy, skewness, and kurtosis[29](#_page9_x155.00_y90.36). Corre- lation-based feature selection was used to reduce the feature size from 209 to 170[26](#_page8_x155.00_y712.36). When the model is unsure if COVID-19 will be detected as yes/no, it provides an inconclusive output as shown in the block diagram Fig[. 1](#_page3_x534.00_y697.36).

**Clinical validation of the model**

In the Clinical validation phase, the trained model was tested on 233 subjects recruited from different locations, including isolation wards and COVID testing centers.  e subjects underwent both the screening test using the model and the standard RT-PCR test for COVID-19 diagnosis.  e test results from both methods were com - pared to each other by a statistician. A consolidated test summary sheet was generated containing the results of both the standard diagnostic testing and the model s output.

**External validation of the model**

During the Pilot Phase, the trained model was externally validated to determine its effectiveness as a screening tool for detecting COVID-19 prior to clinical diagnosis.  e sample size for this phase consisted of 177 indi- viduals who were identified as presumptive COVID-19 cases and recruited from a peripheral healthcare center. To measure the model s effectiveness, the ratio of patients truly diagnosed as COVID-19 positive via standard diagnostic techniques to all those who were predicted to be COVID-19 positive via the model was calculated.  e diagnostic performance of the model was evaluated using various metrics, including sensitivity, specific- ity, positive predictive value (PPV), negative predictive value (NPV), and accuracy. Again, the effectiveness of the model was assessed by comparing it with standard diagnostic methods like RT-PCR, and the results were analysed using statistical methods.

**LIME representation**

` `e green portion of the Local interpretable model-agnostic explanations (LIME) representation27 [il](#_page9_x155.00_y47.36)lustrates instances in which the model responded positively to a given class, whereas the red portion highlights instances in which it responded negatively. To  explain  a prediction, we refer to the display of textual or visual artefacts that give qualitative understanding of the link between the instance s components (such as words in text, patches in a picture, etc.) and the prediction made by the model.

**Statistical significance**

A comprehensive assessment of model performance on the test set includes accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and ROC. To measure the variability of these parameters, we used the Clopper-Pearson  method[28 ](#_page9_x155.00_y73.36)with 95% confidence intervals. To better understand the model s performance in screening COVID-19 subjects, we also calculated the confusion matrix across the test set.

**Results**

**Performance parameters in model derivation phase**

Cough sound data was collected from 252 COVID-19 positive subjects in the derivation phase. Data collected from 390 COVID-19 negative subjects in one of our earlier studies was also considered in this phase. Among 252 subjects, 60% were male and 40% were female, with age ranging from 18 years to 64 & above (F[ig](#_page4_x155.00_y198.36). [2](#_page4_x155.00_y198.36)). Sub- jects were confirmed with COVID-19 by standard diagnosis methods. In this phase multiple data points were collected from the subjects. Each data point was called a record. A total of 803 cough records were collected from 252 patients.

` `e 252 subject data was divided into training (173) and test (79).  e training data was internally divided 

into training and validation as required to build as well as optimize the model performance based on K-fold cross validation technique. All the 252 subject data was annotated with disease condition as COVID-19 i.e., COVID- 19 likely as  yes . For COVID unlikely, data representing other disease conditions was added from pre-existing datasets[29](#_page9_x155.00_y90.36) (collected part of earlier studies) in various propositions. A total of 1213 records data was added to various classifiers.  e final confusion matrix for derivation phase is represented in Table 1[.  ](#_page4_x155.00_y304.36)e performance parameters such as accuracy, sensitivity, specificity, and AUC (Area Under the ROC Curve) of the model in the derivation phase are enlisted in Table [2](#_page4_x155.00_y417.36).  e model s ability to produce accurate predictions is extremely effec - tive, as shown by the AUC score of 0.965.  e ROC curve in Fig. [3 ](#_page4_x155.00_y707.36)illustrates the best-performing fold among the ten cross-validation folds.

` `e model was also evaluated on crowdsourced data, which includes COVID-19 Likely  yes  data from EPFL and Cambridge datasets, whereas COVID-19 Likely  no  is the in-house data.  e final confusion matrix for this dataset is presented in Table [3](#_page5_x155.00_y116.36).  e performance parameters for the same are listed in Table 4.

` `e features listed in Table 5[ d](#_page5_x155.00_y376.36)epicts the mean value of the features extracted from individual frames, where we have considered normal as well as respiratory diseases data other than COVID from our previous validation study conducted at Apollo Hospitals, Hyderabad.

**LIME data comparison**

Extremely low spectral frequencies have been observed in conditions such as COPD and ILD as compared to asthma, which has an intermediate spectral frequency. On the other hand, we found that the spectral components 

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.007.jpeg) ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.008.png)

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.009.jpeg)

<a name="_page3_x534.00_y697.36"></a><a name="_page4_x155.00_y198.36"></a>**Figure 2.**  Data distribution in the derivation phase, validation phase and pilot testing.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.010.png)



<table><tr><th colspan="1" rowspan="2"></th><th colspan="1" rowspan="2"></th><th colspan="2" valign="top"><b>Actual values (ground truths)</b></th><th colspan="1" rowspan="1" valign="bottom"><b>Total</b></th></tr>
<tr><td colspan="1" valign="top"><b>COVID likely YES</b></td><td colspan="1" valign="top"><b>COVID likely NO</b></td></tr>
<tr><td colspan="1" rowspan="3" valign="top">Predicted values</td><td colspan="1" valign="top">COVID likely YES</td><td colspan="1" valign="top">256 (TP)</td><td colspan="1" valign="top">12 (FP)</td><td colspan="1" valign="top">268</td></tr>
<tr><td colspan="1" valign="top">COVID likely NO</td><td colspan="1" valign="top">11 (FN)</td><td colspan="1" valign="top">278 (TN)</td><td colspan="1" valign="top">289</td></tr>
<tr><td colspan="1" valign="top">Total</td><td colspan="1" valign="top">267</td><td colspan="1" valign="top">290</td><td colspan="1" valign="top">557</td></tr>
</table>

<a name="_page4_x155.00_y304.36"></a>**Table 1.**  Final Confusion matrix for the derivation phase.  e values represented in the table are the cough records.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.011.png)



|Accuracy|96%|
| - | - |
|Sensitivity|95\.8%|
|Specificity|95\.6%|
|AUC |0\.95|

<a name="_page4_x155.00_y417.36"></a>**Table 2.**  Performance metrics of the derivation phase.![ref1]

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.013.jpeg)

<a name="_page4_x155.00_y707.36"></a>**Figure 3.**  e representative graph for ROC curve, best among tenfold validation of COVID-19 prediction model built using derivation data.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.014.png)



<table><tr><th colspan="1" rowspan="2"></th><th colspan="1" rowspan="2"></th><th colspan="2" valign="top"><b>Actual values (ground truths)</b></th><th colspan="1" rowspan="1" valign="bottom"><b>Total</b></th></tr>
<tr><td colspan="1" valign="top"><b>COVID likely YES</b></td><td colspan="1" valign="top"><b>COVID likely NO</b></td></tr>
<tr><td colspan="1" rowspan="3" valign="top">Predicted values</td><td colspan="1" valign="top">COVID likely YES</td><td colspan="1" valign="top">527 (TP)</td><td colspan="1" valign="top">57 (FP)</td><td colspan="1" valign="top">584</td></tr>
<tr><td colspan="1" valign="top">COVID likely NO</td><td colspan="1" valign="top">91 (FN)</td><td colspan="1" valign="top">443 (TN)</td><td colspan="1" valign="top">534</td></tr>
<tr><td colspan="1" valign="top">Total</td><td colspan="1" valign="top">618</td><td colspan="1" valign="top">500</td><td colspan="1" valign="top">1118</td></tr>
</table>

<a name="_page5_x155.00_y116.36"></a>**Table 3.**  Final Confusion matrix for the Crowdsource (test) data during derivation phase.  e values represented in the table are the cough records.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.015.png)



|Accuracy|86%|
| - | - |
|Sensitivity|85%|
|Specificity|88%|
|AUC |0\.855|

<a name="_page5_x155.00_y229.36"></a>**Table 4.**  Performance metrics of Crowdsource (test) data during derivation phase.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.016.png)



|**Disease conditions**|**ZCR mean values**|**Spectral centroid mean values**|**Dominant frequency mean values**|
| - | - | - | - |
|Normal|0\.168|2249|844|
|ILD|0\.099|2053|436|
|COPD|0\.08|1947|393|
|Asthma|0\.112|2093|528|
|Pneumonia|0\.118|2249|546|
|COVID-19|0\.246|3710|1287|
|COVID-19 (Low severity)|0\.203|3300|891|

<a name="_page5_x155.00_y376.36"></a>**Table 5.**  Table showing mean values of the Zero crossing rate (ZCR), spectral centroid and dominant frequency of various respiratory disease conditions, including COVID-19.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.017.png)

are very high in diseases in which mucus accumulates in the airways and fluid accumulates in the parenchyma region. High spectral content is the distinguishing feature of COVID-19 cough from other respiratory diseases.

Feature analysis studies of cough sounds have revealed that it could be utilized for distinguishing diseases.  e cough duration and frequency distribution has been found to be unique in a specific respiratory disease, including COVID-19[30](#_page9_x155.00_y107.36)[,31](#_page9_x155.00_y124.36).

We compared the LIME maps of various respiratory diseases with COVID-19 which are enlisted in Table[ 6](#_page6_x155.00_y391.36). It can be seen in the maps that each disease has a unique frequency distribution. Green patches were more dominant for COVID-19 in high frequency regions. Whereas LIME maps for normal subjects were reacting negatively even though it has some green patches present. Similarly, pneumonia maps were also present in the high frequency range but has a stronger predominance in the medium frequency range. Even for Asthma most of the dominant green patches were seen in the medium frequency region.

From the LIME map analysis, we can conclude that COVID-19 related cough has a unique signature.  ese key signatures are detected by features extracted from coughs that can be further identified and characterized by machine learning models.

**Performance parameters of model in validation phase**

Out of 234 subjects participated in the validation phase, 22 were found to be COVID-19 positive and 211 COVID-19 negative by standard diagnostic methods such as RT-PCR. Results of 1 subject remained inconclu- sive, hence didn t consider that datapoint. Confusion matrix for validation phase of the model is illustrated in Table [7](#_page6_x155.00_y516.36), where the row represents the actual label, and the column represents predicted label. An accuracy of 75.54% with 95.45% sensitivity and 73.46% specificity was achieved for the Validation phase (Tab[le](#_page6_x155.00_y688.36) [8](#_page6_x155.00_y688.36)). Also, an AUC (Area Under the ROC Curve) of 0.75 (Fig.[ 4](#_page7_x155.00_y242.36)) was achieved in this phase.

**Model output in the pilot phase**

A total of 183 patients were recruited for the pilot testing phase. Out of these 183 subjects, model was able to identify 82 subjects as having a likely presence of SARS-CoV-2. Out of these 82 subjects, 58 truly turned out to be COVID-19 positive with a Positive predictive value (PPV) of 70.73%.  e confusion matrix for this phase is enlisted in Table[ 9](#_page7_x155.00_y366.36).

**COVID cough LIME maps![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.018.png)**

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.019.png) ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.020.png) ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.021.png)

**Non COVID cough LIME maps**

Normal cough LIME  Pneumonia cough LIME  Asthma cough LIME map map map

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.022.png) ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.023.png) ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.024.png)

<a name="_page6_x155.00_y391.36"></a>**Table 6.**  List of different respiratory diseases showing characteristic cough signature, cough spectrograms and related LIME maps.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.025.png)



<table><tr><th colspan="1" rowspan="2"></th><th colspan="1" rowspan="2"></th><th colspan="2" valign="top"><b>Actual values (ground truths)</b></th><th colspan="1" rowspan="1" valign="bottom"><b>Total</b></th></tr>
<tr><td colspan="1" valign="top"><b>COVID likely YES</b></td><td colspan="1" valign="top"><b>COVID likely NO</b></td></tr>
<tr><td colspan="1" rowspan="3" valign="top">Predicted values</td><td colspan="1" valign="top">COVID likely YES</td><td colspan="1" valign="top">21 (TP)</td><td colspan="1" valign="top">56 (FP)</td><td colspan="1" valign="top">77</td></tr>
<tr><td colspan="1" valign="top">COVID likely NO</td><td colspan="1" valign="top">1 (FN)</td><td colspan="1" valign="top">155 (TN)</td><td colspan="1" valign="top">156</td></tr>
<tr><td colspan="1" valign="top">Total</td><td colspan="1" valign="top">22</td><td colspan="1" valign="top">211</td><td colspan="1" valign="top">233</td></tr>
</table>

<a name="_page6_x155.00_y516.36"></a>**Table 7.**  Confusion matrix for the validation phase.  e values represented in the table are the subject number.![ref2]



|**Statistic**|**Value**|**95% CI**|
| - | - | - |
|Sensitivity|95\.45%|75\.16% to 99.88%|
|Specificity|73\.46%|69\.96% to 79.29%|
|Positive likelihood ratio|3\.60|2\.82 to 4.58|
|Negative likelihood ratio|0\.06|0\.01 to 0.42|
|Disease prevalence|9\.44%|6\.01% to 13.95%|
|Positive predicate value|27\.27%|22\.74% to 32.33%|
|Negative predicate value|99\.36%|95\.80% to 99.91%|
|Accuracy|75\.54%|69\.50% to 80.91%|

<a name="_page6_x155.00_y688.36"></a>**Table 8.**  Performance metrics of the validation phase.![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.027.png)

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.028.jpeg)

<a name="_page7_x155.00_y242.36"></a>**Figure 4.**  e provided ROC curve illustrates the performance of COVID-19 prediction model constructed using validation data.![ref1]



<table><tr><th colspan="1" rowspan="2"></th><th colspan="1" rowspan="2"></th><th colspan="2" valign="top"><b>Actual values (ground truths)</b></th><th colspan="1" rowspan="1" valign="bottom"><b>Total</b></th></tr>
<tr><td colspan="1" valign="top"><b>COVID likely YES</b></td><td colspan="1" valign="top"><b>COVID likely NO</b></td></tr>
<tr><td colspan="1" rowspan="3" valign="top">Predicted values</td><td colspan="1" valign="top">COVID likely YES</td><td colspan="1" valign="top">58 (TP)</td><td colspan="1" valign="top">24 (FP)</td><td colspan="1" valign="top">82</td></tr>
<tr><td colspan="1" valign="top">COVID likely NO</td><td colspan="1" valign="top">47 (FN)</td><td colspan="1" valign="top">48 (TN)</td><td colspan="1" valign="top">95</td></tr>
<tr><td colspan="1" valign="top">Total</td><td colspan="1" valign="top">105</td><td colspan="1" valign="top">72</td><td colspan="1" valign="top">177</td></tr>
</table>

<a name="_page7_x155.00_y366.36"></a>**Table 9.**  Confusion matrix for the pilot phase.  e values represented in the table are the subject number.![ref2]

` `e screening of COVID-19 patients by the model is time saving as compared to the currently used traditional procedures. Additionally, our model does not need any trained professional; a community healthcare worker can also perform the screening.  e technician did not need any specialised equipment or supplies.  e only prerequisites to complete the exam are a smartphone and a stable internet connection.

**Discussion**

` `e sense of urgency in comprehending, detecting, and finding a cure for SARS-CoV-2 has resulted in expedited scientific progress.  is progress has been instrumental in reducing disease transmission through the acquisition 

of crucial knowledge, the implementation of preventive measures, and the advancement of effective  treatments [32](#_page9_x155.00_y149.36). However, the excessive cost of rapid screening diagnostic kits as well as multiple genetic variants of the virus poses a major hindrance in conducting large-scale screening operations[33](#_page9_x155.00_y175.36). Various researchers across the globe are working to find a cost-effective solution to keep a check on the rapidly mutating virus[34](#_page9_x155.00_y192.36)[,35](#_page9_x155.00_y209.36).

Machine learning (ML) has immense potential for accurate and rapid detection of various medical conditions[36](#_page9_x155.00_y226.36), including COVID-19, using computed tomography (CT), chest radiography (CXR), and even coughing pattern[37](#_page9_x155.00_y243.36)[,38](#_page9_x155.00_y260.36). Specifically the information in the cough has been previously applied in the diagnosis and prediction of various diseases, including lung cancer, bronchitis, pneumonia, COPD, and  asthma[39](#_page9_x155.00_y277.36)[,40](#_page9_x155.00_y294.36).

In this study, we developed the model by merging the final output layers of the two separate models i.e., the tabular model (training input: primary and secondary features) and CNN model (training input: MFCC spec -     trograms). Hence, our model provides better prediction outcome as compared to the either logical repression or      CNN model used alone by other researchers[19](#_page8_x155.00_y584.36)[,38](#_page9_x155.00_y260.36)[,41](#_page9_x155.00_y311.36) [44.](#_page9_x155.00_y370.36) We conducted the derivation phase, validation phase and      pilot screening on a comparatively large cohort, whereas previous studies were performed on either smaller scale or crowdsource datasets which are highly unreliable[38](#_page9_x155.00_y260.36). In a prior study the authors extracted the MFCCs from cough recordings and fed them into a pretrained CNN model, which resulted in an AUC (Area Under the ROC      Curve) of 97% with a sensitivity and a specificity of 94.2[%17](#_page8_x155.00_y550.36). Another AI-based COVID-19 cough classifier study includes the analysis of cough recorded over a smartphone, which was able to distinguish COVID-19 positive cases from both COVID-19 negative and healthy coughs. An AUC (Area Under the ROC Curve)of 98% was achieved using the Resnet50 classifier to discriminate between COVID-19 positive and healthy coughs, while to differentiate between COVID-19 positive and negative coughs an LSTM classifier was used with an AUC of 94%[19](#_page8_x155.00_y584.36). In one of the studies both coughs and breathing sounds were used to identify how distinct COVID-19 sounds were as compared to asthma patients or healthy individuals.  ey highlighted that how a simple binary 
machine-learning classifier can distinguish COVID-19 cough sounds from healthy subjects by achieving an overall AUC of above 80[%41](#_page9_x155.00_y311.36). A recent study made use of an ensemble-based multi-criteria decision-making (MCDM) method for detecting COVID-19 from cough sound data and achieved an AUC of 95%[38](#_page9_x155.00_y260.36).

Our model achieved an accuracy of 75.54% with 95.45% sensitivity and 73.46% specificity in the clinical validation phase.  e pilot testing was undertaken in a real primary care setting to test the accuracy of the tool. Upon deployment as a screening and triaging tool prior to molecular testing, this model was proven statistically effective in identifying high-risk patients for confirmatory testing. In the pilot phase also, the model achieved a positive prediction value of 70.73% in a clinical setup at a tertiary care hospital.

Swaasa has been specifically developed as a screening tool with the primary objective of assisting healthcare professionals in identifying individuals who may potentially have COVID-19. By harnessing the capabilities of our advanced model, our aim is to significantly improve the efficiency and precision of the screening process. 

` `is, in turn, facilitates the prioritization of individuals for further evaluation, leading to more targeted and timely interventions for those suspected of being infected with COVID-19. Our model serves as a valuable resource in enhancing the accuracy and effectiveness of COVID-19 screening efforts.

**Data availability**

Due to the nature of this research, participants of this study did not agree for their data to be shared publicly. However, the detailed analysis can be shared by the author  NRS  upon reasonable request.

Received: 29 May 2023; Accepted: 16 October 2023

![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.029.png)

<a name="_page8_x155.00_y270.36"></a>**References**

1. WHO COVID-19 Dashboard. Geneva: World Health Organization, 2020 [Internet].
1. Ong, S. W. X. et al. Air, surface environmental, and personal protective equipment contamination by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) from a symptomatic patient. J. Am. Med. Assoc. **323**, 1610 1612. [https:// doi.org/ 10.1001/](https://doi.org/10.1001/jama.2020.3227) <a name="_page8_x155.00_y304.36"></a>[jama.2020.3227](https://doi.org/10.1001/jama.2020.3227) (2020).
1. Atzrodt, C. L. et al. A Guide to COVID-19: A global pandemic caused by the novel coronavirus SARS-CoV-2. FEBS J. **287**, <a name="_page8_x155.00_y321.36"></a>3633 3650. <https://doi.org/10.1111/febs.15375> (2020).
1. Nalbandian, A. et al. Post-acute COVID-19 syndrome. Nat. Med. **27**, 601 615. <https://doi.org/10.1038/s41591-021-01283-z> (2021).
1. Du, Z. et al. Comparative cost-effectiveness of SARS-CoV-2 testing strategies. SSRN Electron[. J. https://doi. org/10.2139/ssrn.37146](https://doi.org/10.2139/ssrn.3714642) <a name="_page8_x155.00_y346.36"></a>[42](https://doi.org/10.2139/ssrn.3714642) (2020).
1. Tahamtan, A. & Ardebili, A. Real-time RT-PCR in COVID-19 detection: Issues affecting the results. Expert Rev. Mol. Diagn. **20**, <a name="_page8_x155.00_y363.36"></a>453 454. <https://doi.org/10.1080/14737159.2020.1757437> (2020).
1. Alimohamadi, Y., Sepandi, M., Taghdir, M. & Hosamirudsari, H. Determine the most common clinical symptoms in COVID-19 patients: A systematic review and meta-analysis. J. Prev. Med. Hyg. **61**, E304 E312. [https:// doi. org/ 10. 15167/ 2421- 4248/ jpmh2](https://doi.org/10.15167/2421-4248/jpmh2020.61.3.1530) <a name="_page8_x155.00_y389.36"></a>[020.61.3.1530](https://doi.org/10.15167/2421-4248/jpmh2020.61.3.1530) (2020).
1. Chung, K. F. & Pavord, I. D. Prevalence, pathogenesis, and causes of chronic cough. Lancet **371**, 1364 1374. [https://doi.org/10. 1016/S0140-6736(08)60595-4](https://doi.org/10.1016/S0140-6736\(08\)60595-4)<a name="_page8_x155.00_y406.36"></a> (2008).
1. Simonsson, B. G., Jacobs, F. M. & Nadel, J. A. Role of autonomic nervous system and the cough reflex in the increased responsive- <a name="_page8_x155.00_y423.36"></a>ness of airways in patients with obstructive airway disease. J. Clin. Invest. **46**, 1812 1818. <https://doi.org/10.1172/JCI105671> (1967).
1. Song, W.-J. et al. Confronting COVID-19-associated cough and the post-COVID syndrome: Role of viral neurotropism, neuroin- <a name="_page8_x155.00_y440.36"></a>flammation, and neuroimmune responses.  Lancet Respir. Med. **9**, 533 544. <https://doi.org/10.1016/S2213-2600(21)00125-9> (2021).
1. Higenbottam, T. Chronic cough and the cough reflex in common lung diseases. Pulm. Pharmacol.  er. **15**, 241 247. ht[tps://doi. org/10.1006/pupt.2002.0341](https://doi.org/10.1006/pupt.2002.0341)<a name="_page8_x155.00_y457.36"></a> (2002).
1. Kaplan, A. G. Chronic cough in adults: Make the diagnosis and make a difference. Pulm.  er. **5**, 11 21. h[ttps://doi.org/10.1007/ s41030-019-0089-7](https://doi.org/10.1007/s41030-019-0089-7)<a name="_page8_x155.00_y474.36"></a> (2019).
1. Ashby, A. E., Meister, J. A. & Gentzke, W. Cough-based COVID-19 detection with audio quality clustering and confidence measure <a name="_page8_x155.00_y491.36"></a>based learning. Proc. Mach. Learn. Res. **2022**, 1 20 (2022).
1. Sharma, N., Krishnan, P., Kumar, R., Ramoji, S., Chetupalli, S. R., Nirmala, R., Kumar Ghosh, P., Ganapathy, S. Coswara A data- base of breathing, cough, and voice sounds for COVID-19 diagnosis. In Proceedings of the Annual Conference of the International <a name="_page8_x155.00_y516.36"></a>Speech Communication Association INTERSPEECH, 4811 4815, 202[0. https://doi.org/10.21437/Interspeech.2020-2768](https://doi.org/10.21437/Interspeech.2020-2768).
1. Lancet, T. Artificial intelligence in health care: Within touching distance. Lancet **390**, 2739.[ https://doi.org/10.1016/S0140-6736(17)](https://doi.org/10.1016/S0140-6736\(17\)31540-4) <a name="_page8_x155.00_y533.36"></a>[31540-4](https://doi.org/10.1016/S0140-6736\(17\)31540-4) (2017).
1. Ijaz, A. et al. Towards using cough for respiratory disease diagnosis by leveraging Artificial Intelligence: A survey. Inform. Med. <a name="_page8_x155.00_y550.36"></a>Unlocked **29**, 1 28. [https:// doi.org/10.1016/j.imu.2021.100832](https://doi.org/10.1016/j.imu.2021.100832) (2022).
1. Laguarta, J., Hueto, F. & Subirana, B. COVID-19 artificial intelligence diagnosis using only cough recordings. IEEE Open J. Eng. Med. Biol. **1**, 275 281. [https:// doi.org/10.1109/OJEMB.2020.3026928](https://doi.org/10.1109/OJEMB.2020.3026928) (2020).
1. Tena, A., Clari , F. & Solsona, F. Automated detection of COVID-19 cough. Biomed. Signal Process. Contro[l https:// doi. org/ 10. 1016/j.bspc.2021.103175](https://doi.org/10.1016/j.bspc.2021.103175)<a name="_page8_x155.00_y584.36"></a> (2022).
1. Pahar, M., Klopper, M., Warren, R. & Niesler, T. COVID-19 cough classification using machine learning and global smartphone recordings. Comput. Biol. Med. **135**, 1 10. [https://doi. org/10.1016/j.compbiomed.2021.104572](https://doi.org/10.1016/j.compbiomed.2021.104572) (2021).
1. Chowdhury, N. K., Kabir, M. A., Rahman, M. M. An ensemble-based multi-criteria decision making method for COVID-19 cough <a name="_page8_x155.00_y618.36"></a>classification. 2021.
1. Lella, K. K. & Pja, A. Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath. Alex. Eng. J. **61**, 1319 1334. [https://doi.org/10.1016/j.aej.2021.06](https://doi.org/10.1016/j.aej.2021.06.024). <a name="_page8_x155.00_y644.36"></a>[024](https://doi.org/10.1016/j.aej.2021.06.024) (2022).
1. Ashby, A. E., Meister, J. A., Soldar, G., Nguyen, K. A. A novel cough audio segmentation framework for COVID-19 detection. <a name="_page8_x155.00_y661.36"></a>2022. p. 1 8.
1. Chang, J., Ruan, Y., Shaoze, C., Yit, J. S. T., Feng, M. UFRC: A Unified Framework for Reliable COVID-19 Detection on Crowd- <a name="_page8_x155.00_y678.36"></a>sourced Cough Audio. 2022;2 5.
1. Pourhoseingholi, M. A., Vahedi, M. & Rahimzadeh, M. Sample size calculation in medical studies. Gastroenterol. Hepatol. from <a name="_page8_x155.00_y695.36"></a>Bed to Bench **6**, 14 17 (2013).
1. Jones, P. W., Quirk, F. H. & Baveystock, C. M.  e St George s Respiratory Questionnaire. Respir. Med. **85**, 25 31. [https:// doi.org/](https://doi.org/10.1016/S0954-6111\(06\)80166-6) 

   10. [1016/S0954-6111(06)80166-6](https://doi.org/10.1016/S0954-6111\(06\)80166-6)<a name="_page8_x155.00_y712.36"></a> (1991).
1. Yellapu, G. D. et al. Development and clinical validation of Swaasa AI platform for screening and prioritization of pulmonary TB. Sci. Rep. **13**, 4740.[ https://doi.org/10.1038/s41598-023-31772-9](https://doi.org/10.1038/s41598-023-31772-9) (2023).
27. Ribeiro, M., Singh, S., Guestrin, C.  Why Should I Trust You? : Explaining the predictions of any classifier. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, 2016. p. 1135 1144. <a name="_page9_x155.00_y73.36"></a><https://doi.org/10.18653/v1/N16-3020>.
27. Clopper, C. J. & Pearson, E. S.  e use of confidence or fiducial limits illustrated in the case of the binomial. Biometrika **26**, 404 413. <a name="_page9_x155.00_y90.36"></a><https://doi.org/10.1093/biomet/26.4.404> (1934).
27. Rudraraju, G. et al. Cough sound analysis and objective correlation with spirometry and clinical diagnosis. Inform. Med. Unlocked <a name="_page9_x155.00_y107.36"></a>**19**, 1 11. [https:// doi.org/10.1016/j.imu.2020.100319](https://doi.org/10.1016/j.imu.2020.100319) (2020).
27. Turner, R. D. & Bothamley, G. H. Cough and the transmission of tuberculosis. J. Infect. Dis. **211**, 1367 1372. [https://doi.org/10.](https://doi.org/10.1093/infdis/jiu625) <a name="_page9_x155.00_y124.36"></a>[1093/infdis/jiu625](https://doi.org/10.1093/infdis/jiu625) (2015).
27. Belkacem, A. N., Ouhbi, S., Lakas, A., Benkhelifa, E. & Chen, C. End-to-end AI-based point-of-care diagnosis system for classify- ing respiratory illnesses and early detection of COVID-19: A theoretical framework. Front. Med. **8**, 1 13. [https://doi.org/10.3389/ fmed.2021.585578](https://doi.org/10.3389/fmed.2021.585578)<a name="_page9_x155.00_y149.36"></a> (2021).
27. Wiersinga, W. J., Rhodes, A., Cheng, A. C., Peacock, S. J. & Prescott, H. C. Pathophysiology, transmission, diagnosis, and treatment of coronavirus disease 2019 (COVID-19): A review. J. Am. Med. Assoc. **324**, 782 793. <https://doi.org/10.1001/jama.2020.12839> <a name="_page9_x155.00_y175.36"></a>(2020).
27. Schuit, E. et al. Diagnostic accuracy of covid-19 rapid antigen tests with unsupervised self-sampling in people with symptoms in <a name="_page9_x155.00_y192.36"></a>the omicron period: Cross sectional study. BMJ **378**, e071215.[ https://doi.org/10.1136/bmj-2022-071215](https://doi.org/10.1136/bmj-2022-071215) (2022).
27. Marino, F. E., Proffitt, E., Joseph, E. & Manoharan, A. A rapid, specific, extraction-less, and cost-effective RT-LAMP test for the <a name="_page9_x155.00_y209.36"></a>detection of SARS-CoV-2 in clinical specimens. PLoS ONE **17**, 1 15. [https:// doi.org/10.1371/journal.pone.0266703](https://doi.org/10.1371/journal.pone.0266703) (2022).
27. Filchakova, O. et al. Review of COVID-19 testing and diagnostic methods. Talanta **244**, 123409.[ https://doi.org/10.1016/j.talanta.](https://doi.org/10.1016/j.talanta.2022.123409) <a name="_page9_x155.00_y226.36"></a>[2022.123409](https://doi.org/10.1016/j.talanta.2022.123409) (2022).
27. Aggarwal, R. et al. Diagnostic accuracy of deep learning in medical imaging: A systematic review and meta-analysis. NPJ Digit. <a name="_page9_x155.00_y243.36"></a>Med.[ https://doi.org/10.1038/s41746-021-00438-z](https://doi.org/10.1038/s41746-021-00438-z) (2021).
27. Harmon, S. A. et al. Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets. <a name="_page9_x155.00_y260.36"></a>Nat. Commun. **11**, 1 7. [https:// doi.org/10.1038/s41467-020-17971-2](https://doi.org/10.1038/s41467-020-17971-2) (2020).
27. Chowdhury, N. K., Kabir, M. A., Rahman, M. M. & Islam, S. M. S. Machine learning for detecting COVID-19 from cough sounds: <a name="_page9_x155.00_y277.36"></a>An ensemble-based MCDM method. Comput. Biol. Med. **145**, 105405.[ https://doi.org/10.1016/j.compbiomed.2022.105405](https://doi.org/10.1016/j.compbiomed.2022.105405) (2022).
27. Swarnkar, V. et al. Automatic identification of wet and dry cough in pediatric patients with respiratory diseases. Ann. Biomed. Eng. <a name="_page9_x155.00_y294.36"></a>**41**, 1016 1028. <https://doi.org/10.1007/s10439-013-0741-6> (2013).
27. Xu, X. et al. Listen2Cough: Leveraging end-to-end deep learning cough detection model to enhance lung health assessment using <a name="_page9_x155.00_y311.36"></a>passively sensed audio. Proc. ACM Interact. Mobile Wearable Ubiquitous Technol. **5**, 1 22. <https://doi.org/10.1145/3448124> (2021).
27. Brown, C., Chauhan, J., Grammenos, A., Han, J., Hasthanasombat, A., Spathis, D., Xia, T., Cicuta, P., Mascolo, C. Exploring auto- matic diagnosis of COVID-19 from crowdsourced respiratory sound data. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, 3474 3484, 202[0. https://doi.org/10.1145/3394486.3412865](https://doi.org/10.1145/3394486.3412865)
27. Effati, M. & Nejat, G. A performance study of CNN architectures for the autonomous detection of COVID-19 symptoms using cough and breathing. Computers **12**, 44.[ https://doi.org/10.3390/computers12020044](https://doi.org/10.3390/computers12020044) (2023).
27. Ren, K. et al. A COVID-19 medical image classification algorithm based on transformer. Sci. Rep. **13**, 5359.[ https:// doi. org/ 10.](https://doi.org/10.1038/s41598-023-32462-2) <a name="_page9_x155.00_y370.36"></a>[1038/s41598-023-32462-2](https://doi.org/10.1038/s41598-023-32462-2) (2023).
27. Gupta, P. K. et al. COVID-WideNet-A capsule network for COVID-19 detection. Appl. So  Comput. **122**, 108780.[ https://doi.org/](https://doi.org/10.1016/j.asoc.2022.108780) 

    [10.1016/j.asoc.2022.108780](https://doi.org/10.1016/j.asoc.2022.108780) (2022).

**Acknowledgements**

` `is study is supported by the UK Government (British High Commission, New Delhi).  is is a commissioned research report on commercial terms between C-CAMP-FCDO and the UK Government (British High Com - mission, New Delhi). We would also like to acknowledge the team from Andhra Medical College Visakhapatnam for all the support provided.

**Author contributions**

P.P. and D.M.B. defined study protocol, including the study design and methodology. N.R.S. conceptualized the idea of using cough sounds for screening and diagnosing COVID-19. G.R. performed literature review and data analysis. B.M., C.C., C.J., S.D.P. and N.K.R.B. were involved in device development. V.Y. and M.J. created value proposition for the device. S.S. assisted in executing the project at Andhra Medical College by providing all the resources and extending research capabilities. C.G. and G.R. performed data analysis, sample size estimation and result analysis. K.L.P.K., S.S., N.J., V.S.P., S.T., S.V. and V.A. provided subject matter expertise. G.R. and P.F. wrote the manuscript. All the authors provided intellectual inputs and helped in preparing the manuscript.

**Competing interests**

` `e authors declare no competing interests.

**Additional information**

**Correspondence** and requests for materials should be addressed to G.R. **Reprints and permissions information** is available a[t www.nature.com/reprints](www.nature.com/reprints).

**Publisher s note** Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

**Open Access**   is article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made.  e images or other third party material in this ![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.030.png)

article are included in the article s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visi[t http://creativecommons.org/licenses/by/4.0/](http://creativecommons.org/licenses/by/4.0/).

'  e Author(s) 2023
**Scientific Reports** |        (2023) 13:18284  |  https://doi.org/10.1038/s41598-023-45104-4 12![](Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.031.png)

[ref1]: Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.012.png
[ref2]: Aspose.Words.844e7a59-aabd-4bc2-bf95-592c04862160.026.png
